{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aee7c1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a27a03f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset= pd.read_csv('BankNote_Authentication.csv')\n",
    "dataset= pd.read_csv('creditcard.csv')\n",
    "#dataset= pd.read_csv('heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82f82563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "306d5dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ce6bf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= dataset.iloc[:, :-1].values\n",
    "y= dataset.iloc[:, -1].values\n",
    "y = 2*y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfd95049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00 -1.35980713e+00 -7.27811733e-02 ...  1.33558377e-01\n",
      "  -2.10530535e-02  1.49620000e+02]\n",
      " [ 0.00000000e+00  1.19185711e+00  2.66150712e-01 ... -8.98309914e-03\n",
      "   1.47241692e-02  2.69000000e+00]\n",
      " [ 1.00000000e+00 -1.35835406e+00 -1.34016307e+00 ... -5.53527940e-02\n",
      "  -5.97518406e-02  3.78660000e+02]\n",
      " ...\n",
      " [ 1.72788000e+05  1.91956501e+00 -3.01253846e-01 ...  4.45477214e-03\n",
      "  -2.65608286e-02  6.78800000e+01]\n",
      " [ 1.72788000e+05 -2.40440050e-01  5.30482513e-01 ...  1.08820735e-01\n",
      "   1.04532821e-01  1.00000000e+01]\n",
      " [ 1.72792000e+05 -5.33412522e-01 -1.89733337e-01 ... -2.41530880e-03\n",
      "   1.36489143e-02  2.17000000e+02]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a741683a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 ... -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6361ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.918649e-15</td>\n",
       "      <td>5.682686e-16</td>\n",
       "      <td>-8.761736e-15</td>\n",
       "      <td>2.811118e-15</td>\n",
       "      <td>-1.552103e-15</td>\n",
       "      <td>2.040130e-15</td>\n",
       "      <td>-1.698953e-15</td>\n",
       "      <td>-1.893285e-16</td>\n",
       "      <td>-3.147640e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.473120e-16</td>\n",
       "      <td>8.042109e-16</td>\n",
       "      <td>5.282512e-16</td>\n",
       "      <td>4.456271e-15</td>\n",
       "      <td>1.426896e-15</td>\n",
       "      <td>1.701640e-15</td>\n",
       "      <td>-3.662252e-16</td>\n",
       "      <td>-1.217809e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.918649e-15  5.682686e-16 -8.761736e-15  2.811118e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552103e-15  2.040130e-15 -1.698953e-15 -1.893285e-16 -3.147640e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.473120e-16  8.042109e-16  5.282512e-16  4.456271e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.426896e-15  1.701640e-15 -3.662252e-16 -1.217809e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e46507e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_include = ['Time', 'V1', 'V2', 'V28', 'Amount', 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cdc2c2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Use describe() on the subset of columns\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m subset_description \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[columns_to_include]\u001b[38;5;241m.\u001b[39mdescribe()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Extract specific information from the subset description\u001b[39;00m\n\u001b[0;32m      5\u001b[0m count \u001b[38;5;241m=\u001b[39m subset_description\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Use describe() on the subset of columns\n",
    "subset_description = df[columns_to_include].describe()\n",
    "\n",
    "# Extract specific information from the subset description\n",
    "count = subset_description.loc['count']\n",
    "mean = subset_description.loc['mean']\n",
    "std = subset_description.loc['std']\n",
    "min_value = subset_description.loc['min']\n",
    "max_value = subset_description.loc['max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e8795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subset_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3c92c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_description_rounded = subset_description.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc10598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the rounded DataFrame to LaTeX format\n",
    "latex_table_rounded = subset_description_rounded.to_latex()\n",
    "\n",
    "# Write the rounded LaTeX table to a .tex file\n",
    "with open('dataset2b.tex', 'w') as f:\n",
    "    f.write(latex_table_rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d749fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86366978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76be5bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb69664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_loss(X, y, w, b):\n",
    "    # Hinge loss function\n",
    "    return np.maximum(0, 1 - y * (np.dot(X, w) + b))\n",
    "\n",
    "def l1_regularization(w, lam):\n",
    "    # L1 regularization penalty\n",
    "    return lam * np.linalg.norm(w, ord=1)\n",
    "\n",
    "def additional_convex_function(w):\n",
    "    # Additional convex function (can be chosen based on problem requirements)\n",
    "    # For example, the L2 norm of the weight vector\n",
    "    return 0.5 * np.linalg.norm(w)**2\n",
    "\n",
    "def proximal_l1(w, alpha, lam):\n",
    "    # Proximal operator for L1 regularization (soft thresholding)\n",
    "    return np.sign(w) * np.maximum(0, np.abs(w) - alpha * lam)\n",
    "\n",
    "def dc_programming_l1svm(X, y, w_init, b_init, C, lam, lr, max_iter, tol):\n",
    "    # DC programming algorithm for L1-SVM\n",
    "    \n",
    "    # Initialize weights and bias\n",
    "    w = w_init\n",
    "    b = b_init\n",
    "    \n",
    "    # Initialize iteration count\n",
    "    iter_count = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Perform optimization\n",
    "    for i in range(max_iter):\n",
    "        # Compute hinge loss\n",
    "        loss = hinge_loss(X, y, w, b)\n",
    "        \n",
    "        # Compute gradients\n",
    "        grad_w = -np.dot(X.T, y * (loss > 0))\n",
    "        grad_b = -np.sum(y * (loss > 0))\n",
    "        \n",
    "        # Update weights using proximal operator for L1 regularization\n",
    "        w_new = proximal_l1(w - lr * grad_w, lr * C, lam)\n",
    "        \n",
    "        # Update bias\n",
    "        b_new = b - lr * grad_b\n",
    "        \n",
    "        # Check convergence\n",
    "        if np.linalg.norm(w_new - w) < tol:\n",
    "            break\n",
    "        \n",
    "        # Update weights and bias for next iteration\n",
    "        w = w_new\n",
    "        b = b_new\n",
    "        \n",
    "        end_time = time.time()\n",
    "        time_taken = end_time - start_time\n",
    "        # Increment iteration count\n",
    "        iter_count += 1\n",
    "    \n",
    "    return w, b, iter_count, time_taken\n",
    "\n",
    "# Example usage\n",
    "# X: feature matrix, y: labels (-1 for negative class, +1 for positive class)\n",
    "# w_init: initial weight vector, b_init: initial bias, C: regularization parameter for SVM\n",
    "# lam: regularization parameter for L1 penalty, lr: learning rate, max_iter: maximum iterations\n",
    "# tol: convergence tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94201150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_loss(X, y, w, b):\n",
    "    # Hinge loss function\n",
    "    return np.maximum(0, 1 - y * (np.dot(X, w) + b))\n",
    "\n",
    "def proximal_f(x,lam):\n",
    "    # Proximal operator for f(x) = 0.5 * ||x||^2\n",
    "    return x / (1 + lam)  # where alpha is the step size\n",
    "\n",
    "def proximal_g(x, lam):\n",
    "    # Proximal operator for L1 regularization g(x)\n",
    "    return np.sign(x) * np.maximum(np.abs(x) - lam, 0)\n",
    "\n",
    "def grad_h(X, y, w, b):\n",
    "    # Gradient of the hinge loss function\n",
    "    loss = hinge_loss(X, y, w, b)\n",
    "    grad_w = -np.dot(X.T, y * (loss > 0))\n",
    "    grad_b = -np.sum(y * (loss > 0))\n",
    "    return grad_w, grad_b\n",
    "\n",
    "def dc_programming_Alg1(X, y, w_init, b_init, C, lam, lr, max_iter, tol):\n",
    "    # DC programming algorithm for L1-SVM\n",
    "    \n",
    "    # Initialize weights and bias\n",
    "    w = w_init\n",
    "    v = w_init  # Initialize v with the same value as w\n",
    "    \n",
    "    # Initialize iteration count\n",
    "    iter_count = 0\n",
    "    \n",
    "    # Define constants\n",
    "    tht = 0.001\n",
    "    kap = 0.3\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Perform optimization\n",
    "    for i in range(max_iter):\n",
    "        # Compute hinge loss\n",
    "        loss = hinge_loss(X, y, w, b_init)\n",
    "        \n",
    "        grad_h_w, grad_h_b = grad_h(X, y, w, b_init)\n",
    "        \n",
    "       # Update u and y\n",
    "        un = 1 / (1 + tht) * w + tht / (1 + tht) * v\n",
    "        yn = proximal_f(un,lam)\n",
    "        \n",
    "        # Update z and w_new\n",
    "        zn = proximal_g(2 * yn - un - C * grad_h_w, lam)\n",
    "        w_new = un + kap * (zn - yn)\n",
    "        \n",
    "        # Update v_new\n",
    "        v_new = 1 / (tht + 1) * w_new + tht / (1 + tht) * v\n",
    "        \n",
    "        # Check convergence\n",
    "        if np.linalg.norm(w_new - w) < tol:\n",
    "            break\n",
    "        \n",
    "        # Update weights and v for next iteration\n",
    "        w = w_new\n",
    "        v = v_new\n",
    "        \n",
    "        end_time = time.time()\n",
    "        time_taken = end_time - start_time\n",
    "        # Increment iteration count\n",
    "        iter_count += 1\n",
    "    \n",
    "    return w, b_init, iter_count, time_taken\n",
    "\n",
    "# Example usage\n",
    "# X: feature matrix, y: labels (-1 for negative class, +1 for positive class)\n",
    "# w_init: initial weight vector, b_init: initial bias, C: regularization parameter for SVM\n",
    "# lam: regularization parameter for L1 penalty, lr: learning rate, max_iter: maximum iterations\n",
    "# tol: convergence tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32e89a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dc_programming_Alg2(X, y, w_init, b_init, C, lam, lr, max_iter, tol):\n",
    "    # DC programming algorithm for L1-SVM\n",
    "    \n",
    "    # Initialize weights and bias\n",
    "    w = w_init\n",
    "    v = w_init  # Initialize v with the same value as w\n",
    "    \n",
    "    # Initialize iteration count\n",
    "    iter_count = 0\n",
    "    \n",
    "    # Define constants\n",
    "    \n",
    "    kap = 0.1\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Perform optimization\n",
    "    for i in range(max_iter):\n",
    "        # Compute hinge loss\n",
    "        alpha = 1/(500*i+500)\n",
    "        loss = hinge_loss(X, y, w, b_init)\n",
    "        \n",
    "        grad_h_w, grad_h_b = grad_h(X, y, w, b_init)\n",
    "        \n",
    "       # Update u and y\n",
    "        un = (1-alpha) * w + alpha * v\n",
    "        yn = proximal_f(un,lam)\n",
    "        \n",
    "        # Update z and w_new\n",
    "        zn = proximal_g(2 * yn - un - C * grad_h_w, lam)\n",
    "        w_new = zn + kap * (zn - yn)\n",
    "        \n",
    "        # Update v_new\n",
    "        v_new = (1-alpha) * w_new + alpha * v\n",
    "        \n",
    "        # Check convergence\n",
    "        if np.linalg.norm(w_new - w) < tol:\n",
    "            break\n",
    "        \n",
    "        # Update weights and v for next iteration\n",
    "        w = w_new\n",
    "        v = v_new\n",
    "        \n",
    "        end_time = time.time()\n",
    "        time_taken = end_time - start_time\n",
    "        # Increment iteration count\n",
    "        iter_count += 1\n",
    "    \n",
    "    return w, b_init, iter_count, time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc424b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dc_programming_DCA(X, y, w_init, b_init, C, lam, lr, max_iter, tol):\n",
    "    # DC programming algorithm for L1-SVM\n",
    "    \n",
    "    # Initialize weights and bias\n",
    "    w = w_init\n",
    "    v = w_init  # Initialize v with the same value as w\n",
    "    \n",
    "    # Initialize iteration count\n",
    "    iter_count = 0\n",
    "    \n",
    "    # Define constants\n",
    "    tht = 0.1\n",
    "    kap = 0.01\n",
    "    alpha = 0.0003\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Perform optimization\n",
    "    for i in range(max_iter):\n",
    "        # Compute hinge loss\n",
    "        loss = hinge_loss(X, y, w, b_init)\n",
    "        \n",
    "        grad_h_w, grad_h_b = grad_h(X, y, w, b_init)\n",
    "        \n",
    "       # Update u and y\n",
    "       # un = (1-alpha) * w + alpha * v\n",
    "        yn = proximal_f(w,lam)\n",
    "        \n",
    "        # Update z and w_new\n",
    "        zn = proximal_g(2 * yn - w - C * grad_h_w, lam)\n",
    "        w_new = zn + kap * (zn - yn)\n",
    "        \n",
    "        # Update v_new\n",
    "       # v_new = (1-alpha) * w_new + alpha * v\n",
    "        \n",
    "        # Check convergence\n",
    "        if np.linalg.norm(w_new - w) < tol:\n",
    "            break\n",
    "        \n",
    "        # Update weights and v for next iteration\n",
    "        w = w_new\n",
    "        #v = v_new\n",
    "        \n",
    "        end_time = time.time()\n",
    "        time_taken = end_time - start_time\n",
    "        # Increment iteration count\n",
    "        iter_count += 1\n",
    "    \n",
    "    return w, b_init, iter_count, time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca527c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dc_programming_GDCP(X, y, w_init, b_init, C, lam, lr, max_iter, tol):\n",
    "    # DC programming algorithm for L1-SVM\n",
    "    \n",
    "    # Initialize weights and bias\n",
    "    w = w_init\n",
    "    ix = w_init  # Initialize v with the same value as w\n",
    "    \n",
    "    # Initialize iteration count\n",
    "    iter_count = 0\n",
    "    \n",
    "    # Define constants\n",
    "    tht = 0.1\n",
    "    kap = 0.05\n",
    "    alpha = 0.0001\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Perform optimization\n",
    "    for i in range(max_iter):\n",
    "        # Compute hinge loss\n",
    "        loss = hinge_loss(X, y, w, b_init)\n",
    "        \n",
    "        grad_h_w, grad_h_b = grad_h(X, y, w, b_init)\n",
    "        \n",
    "       # Update u and y\n",
    "        un = w  + alpha * (w - ix)\n",
    "        yn = proximal_f(w,lam)\n",
    "        \n",
    "        # Update z and w_new\n",
    "        zn = proximal_g(2 * yn - un - C * grad_h_w, lam)\n",
    "        w_new = zn + kap * (zn - yn)\n",
    "        \n",
    "        # Update v_new\n",
    "       # v_new = (1-alpha) * w_new + alpha * v\n",
    "        \n",
    "        # Check convergence\n",
    "        if np.linalg.norm(w_new - w) < tol:\n",
    "            break\n",
    "        \n",
    "        # Update weights and v for next iteration\n",
    "        ix = w\n",
    "        w = w_new\n",
    "        \n",
    "        \n",
    "        end_time = time.time()\n",
    "        time_taken = end_time - start_time\n",
    "        # Increment iteration count\n",
    "        iter_count += 1\n",
    "    \n",
    "    return w, b_init, iter_count, time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d20ca0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X, y are already loaded\n",
    "# Initialize parameters\n",
    "w_init = np.zeros(X.shape[1])\n",
    "b_init = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfcfbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to the algorithm converging to zeros, we want to try different techniques to resolve this.\n",
    "# 1. Initialize the starting weight and bias to non-zero vectors as follows:\n",
    "\n",
    "# Define the dimensions of the weight vector\n",
    "num_features = X.shape[1]\n",
    "\n",
    "# Initialize weights with small random values\n",
    "w_init = np.random.randn(num_features) * 0.01\n",
    "\n",
    "# Initialize bias with a small random value\n",
    "b_init = np.random.randn() * 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfea1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1  # regularization parameter for SVM\n",
    "lam = 0.01  # regularization parameter for L1 penalty\n",
    "lr = 0.03  # learning rate\n",
    "max_iter = 2000\n",
    "tol = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf6fb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DC programming algorithm for L1-SVM\n",
    "w_final_GD, b_final_GD, iter_count_GD, time_taken_GD = dc_programming_l1svm(X_train, y_train, w_init, b_init, C, lam, lr, max_iter, tol)\n",
    "w_final_Alg1, b_final_Alg1, iter_count_Alg1, time_taken_Alg1 = dc_programming_Alg1(X_train, y_train, w_init, b_init, C, lam, lr, max_iter, tol)\n",
    "w_final_Alg2, b_final_Alg2, iter_count_Alg2, time_taken_Alg2 = dc_programming_Alg2(X_train, y_train, w_init, b_init, C, lam, lr, max_iter, tol)\n",
    "w_final_DCA, b_final_DCA, iter_count_DCA, time_taken_DCA = dc_programming_DCA(X_train, y_train, w_init, b_init, C, lam, lr, max_iter, tol)\n",
    "w_final_GDCP, b_final_GDCP, iter_count_GDCP, time_taken_GDCP = dc_programming_GDCP(X_train, y_train, w_init, b_init, C, lam, lr, max_iter, tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ad4e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal weight vector for GD:\", w_final_GD)\n",
    "print(\"Optimal bias for GD:\", b_final_GD)\n",
    "print(\"Number of iterations for GD:\", iter_count_GD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc79a93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Time taken for training by GD:\", time_taken_GD)\n",
    "print(\"Time taken for training by Alg1:\", time_taken_Alg1)\n",
    "print(\"Time taken for training by Alg2:\", time_taken_Alg2)\n",
    "print(\"Time taken for training by DCA:\", time_taken_DCA)\n",
    "print(\"Time taken for training by GDCP:\", time_taken_GDCP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95250d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w, b):\n",
    "    # Predict labels using the trained model\n",
    "    y_pred = np.sign(np.dot(X, w) + b)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "# Assuming you have a test set X_test and corresponding true labels y_test\n",
    "# X_test: feature matrix of the test set, y_test: true labels of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f34759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred_GD = predict(X_test, w_final_GD, b_final_GD)\n",
    "y_pred_Alg1 = predict(X_test, w_final_Alg1, b_final_Alg1)\n",
    "y_pred_Alg2 = predict(X_test, w_final_Alg2, b_final_Alg2)\n",
    "y_pred_DCA = predict(X_test, w_final_DCA, b_final_DCA)\n",
    "y_pred_GDCP = predict(X_test, w_final_GDCP, b_final_GDCP)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_GD = np.mean(y_pred_GD == y_test)\n",
    "accuracy_Alg1 = np.mean(y_pred_Alg1 == y_test)\n",
    "accuracy_Alg2 = np.mean(y_pred_Alg2 == y_test)\n",
    "accuracy_DCA = np.mean(y_pred_DCA == y_test)\n",
    "accuracy_GDCP = np.mean(y_pred_GDCP == y_test)\n",
    "\n",
    "print(\"Accuracy for GD:\", accuracy_GD)\n",
    "print(\"Accuracy for Alg1:\", accuracy_Alg1)\n",
    "print(\"Accuracy for Alg2:\", accuracy_Alg2)\n",
    "print(\"Accuracy for DCA:\", accuracy_DCA)\n",
    "print(\"Accuracy for GDCP:\", accuracy_GDCP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c409e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "# Assuming y_true contains the true labels and y_pred contains the predicted labels\n",
    "precision_GD = precision_score(y_test, y_pred_GD)\n",
    "precision_Alg1 = precision_score(y_test, y_pred_Alg1)\n",
    "precision_Alg2 = precision_score(y_test, y_pred_Alg2)\n",
    "precision_DCA = precision_score(y_test, y_pred_DCA)\n",
    "precision_GDCP = precision_score(y_test, y_pred_GDCP)\n",
    "\n",
    "print(\"Precision for GD:\", precision_GD)\n",
    "print(\"Precision for Alg1:\", precision_Alg1)\n",
    "print(\"Precision for Alg2:\", precision_Alg2)\n",
    "print(\"Precision for DCA:\", precision_DCA)\n",
    "print(\"Precision for GDCP:\", precision_GDCP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b13e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    # Calculate MAE, MSE, RMSE\n",
    "    n = len(y_true)\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return mae, mse, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ca4a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have true labels y_true and predicted labels y_pred\n",
    "# Calculate metrics\n",
    "#y_true = y.reshape(len(y_pred),1)\n",
    "y_true = y_test\n",
    "#y_true = y[:len(y_pred)]\n",
    "mae_GD, mse_GD, rmse_GD = calculate_metrics(y_true, y_pred_GD)\n",
    "mae_Alg1, mse_Alg1, rmse_Alg1 = calculate_metrics(y_true, y_pred_Alg1)\n",
    "mae_Alg2, mse_Alg2, rmse_Alg2 = calculate_metrics(y_true, y_pred_Alg2)\n",
    "mae_DCA, mse_DCA, rmse_DCA = calculate_metrics(y_true, y_pred_DCA)\n",
    "mae_GDCP, mse_GDCP, rmse_GDCP = calculate_metrics(y_true, y_pred_GDCP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac427aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Absolute Error for GD (MAE):\", mae_GD)\n",
    "print(\"Mean Squared Error for GD (MSE):\", mse_GD)\n",
    "print(\"Root Mean Squared Error for GD (RMSE):\", rmse_GD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5720c5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Absolute Error for Alg1 (MAE):\", mae_Alg1)\n",
    "print(\"Mean Squared Error for Alg1 (MSE):\", mse_Alg1)\n",
    "print(\"Root Mean Squared Error for Alg1 (RMSE):\", rmse_Alg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84819808",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Absolute Error for Alg2 (MAE):\", mae_Alg2)\n",
    "print(\"Mean Squared Error for Alg2 (MSE):\", mse_Alg2)\n",
    "print(\"Root Mean Squared Error for Alg2 (RMSE):\", rmse_Alg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c352ad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Absolute Error for DCA (MAE):\", mae_DCA)\n",
    "print(\"Mean Squared Error for DCA (MSE):\", mse_DCA)\n",
    "print(\"Root Mean Squared Error for DCA (RMSE):\", rmse_DCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1015e5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Absolute Error for GDCP (MAE):\", mae_GDCP)\n",
    "print(\"Mean Squared Error for GDCP (MSE):\", mse_GDCP)\n",
    "print(\"Root Mean Squared Error for GDCP (RMSE):\", rmse_GDCP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3a16cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have calculated MAE, MSE, and RMSE values\n",
    "# Example usage\n",
    "mae_values_GD = [mae_GD]\n",
    "mae_values_Alg1 = [mae_Alg1]\n",
    "mae_values_Alg2 = [mae_Alg2]\n",
    "mae_values_DCA = [mae_DCA]\n",
    "mae_values_GDCP = [mae_GDCP]\n",
    "#mse_values = [mse]\n",
    "#rmse_values = [rmse]\n",
    "\n",
    "# Create a box plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "#plt.boxplot([mae_values_GD, mse_values, rmse_values], labels=['MAE', 'MSE', 'RMSE'])\n",
    "plt.boxplot([mae_values_GD, mae_values_Alg1, mae_values_Alg2, mae_values_DCA, mae_values_GDCP], labels=['ADMM', 'Alg1', 'Alg2', 'DCA', 'GDCP'])\n",
    "plt.title('MAE Comparison')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True)\n",
    "plt.savefig('dataset2_40_mae.eps', format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23c9ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_values_GD = [mse_GD]\n",
    "mse_values_Alg1 = [mse_Alg1]\n",
    "mse_values_Alg2 = [mse_Alg2]\n",
    "mse_values_DCA = [mse_DCA]\n",
    "mse_values_GDCP = [mse_GDCP]\n",
    "#mse_values = [mse]\n",
    "#rmse_values = [rmse]\n",
    "\n",
    "# Create a box plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "#plt.boxplot([mae_values_GD, mse_values, rmse_values], labels=['MAE', 'MSE', 'RMSE'])\n",
    "plt.boxplot([mse_values_GD, mse_values_Alg1, mse_values_Alg2, mse_values_DCA, mse_values_GDCP], labels=['ADMM', 'Alg1', 'Alg2', 'DCA', 'GDCP'])\n",
    "plt.title('MSE Comparison')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True)\n",
    "plt.savefig('dataset2_40_mse.eps', format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157d6d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_values_GD = [rmse_GD]\n",
    "rmse_values_Alg1 = [rmse_Alg1]\n",
    "rmse_values_Alg2 = [rmse_Alg2]\n",
    "rmse_values_DCA = [rmse_DCA]\n",
    "rmse_values_GDCP = [rmse_GDCP]\n",
    "#mse_values = [mse]\n",
    "#rmse_values = [rmse]\n",
    "\n",
    "# Create a box plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "#plt.boxplot([mae_values_GD, mse_values, rmse_values], labels=['MAE', 'MSE', 'RMSE'])\n",
    "plt.boxplot([rmse_values_GD, rmse_values_Alg1, rmse_values_Alg2, rmse_values_DCA, rmse_values_GDCP], labels=['ADMM', 'Alg1', 'Alg2', 'DCA', 'GDCP'])\n",
    "plt.title('RMSE Comparison')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True)\n",
    "plt.savefig('dataset2_40_rmse.eps', format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf67282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b942d563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
